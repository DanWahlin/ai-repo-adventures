<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quest 3: Nebular Analytics - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }
        
        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body>

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="index.html">Cosmic Code Chronicles: The Quest for Stellar Harmony</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <a href="https://github.com/danwahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 3: Nebular Analytics</h1>
<hr>
<p>As the <em>SS Code Explorer</em> ventures deeper into the fragmented Repository Galaxy, your instruments detect a peculiar disturbance rippling through the cosmic flows of data. The disturbance appears to be emanating from the Nebular Analytics quadrant‚Äîa critical nexus responsible for generating insights throughout the galaxy. The central mechanisms of analytics are malfunctioning, impacting critical decision systems. Now, it is your mission to restore the channel between the repository analyzer and the neural LLM interpreters, reviving the galaxy&#39;s cosmic wisdom.  </p>
<p><strong>Adventure awaits‚Äîwill you navigate the intricacies of this celestial puzzle?</strong>  </p>
<h2>Quest Objectives</h2>
<p>As you explore the code below, investigate these key questions:  </p>
<ul>
<li>üîç <strong>System Interlink Probe</strong>: How does <code class="inline-code">generateResponse</code> interact with its configuration to form adaptive LLM requests, and how does it respond to errors?  </li>
<li>‚ö° <strong>Optimization Circuit</strong>: What strategies does <code class="inline-code">generateOptimizedContent</code> use to minimize processing overhead and ensure effective content extraction?  </li>
<li>üõ°Ô∏è <strong>Safeguard Protocols</strong>: How do <code class="inline-code">validateProjectPath</code> and <code class="inline-code">validateAndNormalizeTargetFiles</code> ensure file system security and prevent invalid operations?</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">packages/core/src/analyzer/repo-analyzer.ts:</span> Repository Analysis Subsystem</h3>
<p>The <code class="inline-code">RepoAnalyzer</code> subsystem acts as the <em>repository navigator</em>, extracting actionable information from codebases with efficiency. Its operations include targeted file processing and optimization to mitigate token consumption for higher-level LLM interactions. <code class="inline-code">generateOptimizedContent</code> contributes by distilling functions that matter most, while <code class="inline-code">validateAndNormalizeTargetFiles</code> reinforces operational security by sanitizing critical file paths. These functions collectively reinforce the analytical backbone of Nebular Analytics.  </p>
<h4>Highlights</h4>
<ul>
<li><code class="inline-code">generateRepomixContext</code>: Builds corpus-wide representation using Repomix, leveraging caching and fallback mechanisms for scalable content retrieval.  </li>
<li><code class="inline-code">generateOptimizedContent</code>: Extracts function-specific content based on predefined optimization patterns, minimizing noise in large codebases.  </li>
<li><code class="inline-code">validateAndNormalizeTargetFiles</code>: Scrutinizes and prepares file paths for safe repository traversal‚Äîdeflecting injection and traversal threats.</li>
</ul>
<h3><span class="header-prefix">packages/core/src/llm/llm-client.ts:</span> Neural Beacon Interface</h3>
<p>The <code class="inline-code">LLMClient</code> operates as the communication relay between the ship and adaptive language processing systems. It enables refined queries against LLM endpoints and implements protocols for seamless interaction with evolving APIs. The <code class="inline-code">generateResponse</code> function leads this effort, wrapping requests for AI generations, while maintaining error mitigation protocols critical to stable analytics.  </p>
<h4>Highlights</h4>
<ul>
<li><code class="inline-code">generateResponse</code>: Builds and dispatches analytics queries dynamically, parsing responses while safeguarding against anomalies.  </li>
<li><code class="inline-code">constructor</code>: Sets up the LLM client interface by interpreting configuration and alignment with service endpoints (e.g., OpenAI, Azure).  </li>
<li><code class="inline-code">getApiKey</code>: Dynamically determines API keys based on the service provider, managing secure access to the interstellar LLMs.</li>
</ul>
<hr>
<h2>Code</h2>
<h3>packages/core/src/analyzer/repo-analyzer.ts</h3>
<pre><code class="language-typescript">async generateRepomixContext(projectPath: string, options: RepomixOptions = {}): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);

  const configuredFiles = extractUniqueFilePaths(projectPath);

  if (configuredFiles.length &gt; 0) {
    console.log(`Using adventure.config.json: analyzing ${configuredFiles.length} configured files with optimization`);
    try {
      return await this.generateOptimizedContent(projectPath, configuredFiles);
    } catch (error) {
      console.warn(`Failed to generate optimized content, falling back to targeted content`);
      try {
        return await this.generateTargetedContent(projectPath, configuredFiles);
      } catch {
        console.warn(`Fallback failed‚Äîdefaulting to full repomix content`);
      }
    }
  }

  console.log(&#39;Analyzing entire project...&#39;);
  return await this.generateTargetedContent(projectPath, []);
}
</code></pre>
<ul>
<li>Integrates fallback logic for resiliency: optimized, targeted, or full analysis based on external conditions.  </li>
<li>Designs output pipelines to minimize token inefficiency without sacrificing thoroughness.  </li>
<li>Leverages <code class="inline-code">extractUniqueFilePaths</code> for integration with configuration systems like <code class="inline-code">adventure.config.json</code>.</li>
</ul>
<pre><code class="language-typescript">async generateOptimizedContent(projectPath: string, targetFiles: string[], compress: boolean = true): Promise&lt;string&gt; {
  const safeFiles = this.validateAndNormalizeTargetFiles(projectPath, targetFiles);

  const cacheKey = `${path.resolve(projectPath)}:optimized:${safeFiles.join(&#39;,&#39;)}:compress=${compress}`;
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }

  const fullContent = await this.generateTargetedContent(projectPath, targetFiles, compress);
  const optimizedContent = this.extractFunctionFocusedContent(fullContent);

  this.cache.set(cacheKey, { content: optimizedContent, timestamp: Date.now() });
  return optimizedContent;
}
</code></pre>
<ul>
<li>Applies caching to avoid redundant recalculations.  </li>
<li>Refines large codebases by capturing only &quot;important&quot; functions according to pre-defined patterns.  </li>
<li>Encourages modular and token-efficient generation pipelines.</li>
</ul>
<pre><code class="language-typescript">private validateAndNormalizeTargetFiles(projectPath: string, targetFiles: string[]): string[] {
  const MAX_TARGET_FILES = 50; 
  const projectRoot = path.resolve(projectPath);

  const safeFiles = [...new Set(targetFiles)]
    .map(file =&gt; path.resolve(projectPath, file))
    .filter(fullPath =&gt; fullPath.startsWith(projectRoot))
    .slice(0, MAX_TARGET_FILES);

  return safeFiles.map(file =&gt; path.relative(projectPath, file));
}  
</code></pre>
<ul>
<li>Protects against path-traversal exploits by resolving and validating absolute paths.  </li>
<li>Enforces logical file limits (50 entries) to avoid resource depletion during analysis.  </li>
<li>Ensures redundant inputs are filtered out for optimal downstream performance.</li>
</ul>
<hr>
<h3>packages/core/src/llm/llm-client.ts</h3>
<pre><code class="language-typescript">async generateResponse(prompt: string, options?: LLMRequestOptions): Promise&lt;LLMResponse&gt; {
  try {
    const requestParams = this.buildRequestParams(prompt, options);
    const completion = await this.executeRequest(requestParams);
    const content = this.validateResponse(completion);
    return { content };
  } catch (error) {
    this.logDetailedError(error, prompt);
    throw new Error(`LLM request failed: ${error.message}`);
  }
}
</code></pre>
<ul>
<li>Central function handling LLM communication, including retries and adaptive queries.  </li>
<li>Uses <code class="inline-code">validateResponse</code> to ensure received data fits expected formats, preventing application crashes.  </li>
<li>Employs <code class="inline-code">logDetailedError</code> for enhanced debugging under failure scenarios.</li>
</ul>
<pre><code class="language-typescript">constructor() {
  this.model = LLM_MODEL;

  const apiKey = this.getApiKey();
  if (!apiKey || !LLM_BASE_URL) {
    throw new Error(&#39;LLM configuration required. Please set LLM_BASE_URL and appropriate API key.&#39;);
  }

  if (this.isAzureOpenAI()) {
    const azureEndpoint = LLM_BASE_URL.split(&#39;/openai/deployments&#39;)[0];
    this.client = new AzureOpenAI({ endpoint: azureEndpoint, apiKey, apiVersion: LLM_API_VERSION, deployment: this.model });
  } else {
    this.client = new OpenAI({ apiKey, baseURL: LLM_BASE_URL });
  }
}
</code></pre>
<ul>
<li>Dynamically selects LLM provider configurations (OpenAI, Azure) based on contextual requirements.  </li>
<li>Validates that <code class="inline-code">LLM_API_KEY</code>, and <code class="inline-code">LLM_BASE_URL</code> are provided for secure endpoint communication.  </li>
<li>Abstracts backend complexity for seamless initialization of LLM models.</li>
</ul>
<pre><code class="language-typescript">private getApiKey(): string {
  if (LLM_BASE_URL.includes(&#39;azure.com&#39;)) return GITHUB_TOKEN;
  if (!LLM_API_KEY) throw new Error(&#39;No API key available&#39;);
  return LLM_API_KEY;
}
</code></pre>
<ul>
<li>Determines the correct API key dynamically, reflecting different vendor-specific authentication mechanisms.  </li>
<li>Implements clear error reporting for missing credentials, improving developer experience.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>To unlock deeper understanding, observe how caching in <code class="inline-code">generateOptimizedContent</code> reduces redundant calculations.  </li>
<li>Investigate <code class="inline-code">generateResponse</code> for techniques in dynamic query generation for adaptive APIs.  </li>
<li>Explore how file sanitization routines in <code class="inline-code">validateAndNormalizeTargetFiles</code> work to reduce security risks.</li>
</ul>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries.</p>
<p>Starship Nebula has charted a brilliant course through Quest 3: Nebular Analytics, propelling us to 40% mission completion‚Äîstellar work, cosmic explorer!üöÄüíé‚≠ê</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-2.html" class="prev-quest-btn">‚Üê Previous: Quest 2</a>
        <a href="quest-4.html" class="next-quest-btn">Next: Quest 4 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
</body>
</html>