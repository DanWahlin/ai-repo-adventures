<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quest 3: Cosmic Signal Pipeline - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="assets/quest-navigator.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }
        
        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body>

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="index.html">Starship RepoVenture: Charting the Code Galaxy</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <a href="https://github.com/danwahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="assets/images/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 3: Cosmic Signal Pipeline</h1>
<hr>
<p>The command bridge hums as the reactors funnel fresh context into the LLM core. Your scanners isolate a narrowband cosmic signal drifting across the repo nebula. The onboard AI requests precise alignments: validate the hull against malformed coordinates, shape the signal into OpenAI packets, and trigger Repomix bursts without breaching the buffer event horizon. Your task: map this signal pipeline end to end, tracing how requests launch, survive time dilation, and return with usable stardust. Calibrate the analyzers and ensure the telemetry is clean. The galaxy of your project awaits new constellations.</p>
<h2>Quest Objectives</h2>
<p>As you explore the code below, investigate these key questions:</p>
<ul>
<li>üîç Scanner Calibration: How does <code class="inline-code">validateProjectPath</code> guard against malformed or unsafe paths before any subprocess ignition?</li>
<li>‚ö° Burst Transmission Flow: In what sequence do <code class="inline-code">generateTargetedContent</code> and <code class="inline-code">captureRepomixStdout</code> translate file selections into a controlled Repomix subprocess stream?</li>
<li>üõ°Ô∏è Signal Safeguards: How does <code class="inline-code">generateResponse</code> combine request param building, timeout racing, and response validation to protect the pipeline from silent failures and time drifts?</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">packages/core/src/analyzer/repo-analyzer.ts:</span> Analyzer and subprocess propulsion for Repomix context</h3>
<p>This analyzer module orchestrates targeted and full-spectrum Repomix context captures, acting as the ship‚Äôs scanner array. The flow begins with <code class="inline-code">validateProjectPath</code>, a hull integrity check preventing null bytes or blank coordinates from compromising navigation. When seeking targeted signals, <code class="inline-code">generateTargetedContent</code> normalizes and constrains file vectors, constructs a stable cache key to conserve reactor cycles, then configures Repomix CLI options for focused extraction. The actual transmission is delegated to <code class="inline-code">captureRepomixStdout</code>, which spawns <code class="inline-code">npx repomix</code> in a controlled chamber, enforces a strict subprocess timeout window, guards against buffer singularities via <code class="inline-code">REPOMIX_MAX_BUFFER_SIZE</code>, and resolves only when output is valid and non-empty. Together, these functions maintain a reliable telemetry loop: inputs are sanitized, subprocess thrust is time-limited, and outputs are cached for efficient reentry. This design also tolerates turbulence through careful error messages and partial fallbacks in other methods of the class. The architectural pattern emphasizes a secure perimeter (validation), deterministic routing (stable keys and sorted file lists), and resource shields (timeouts, graceful kill, forced kill). Readers should focus on how arguments are assembled for Repomix, where compression toggles influence payload size, and how include lists become CLI parameters to carve precise nebula slices.</p>
<h4>Highlights</h4>
<ul>
<li><code class="inline-code">generateRepomixContext</code> orchestrates full or configured scans, applies caching, and sets compression/ignore patterns to balance fidelity and token economy.</li>
<li><code class="inline-code">generateTargetedContent</code> narrows the scan to specific files, builds a stable cache key, and forms precise Repomix CLI options for minimal drift.</li>
<li><code class="inline-code">captureRepomixStdout</code> performs the subprocess launch, enforces timeouts and buffer limits, and resolves only on valid output to prevent telemetry corruption.</li>
<li><code class="inline-code">validateProjectPath</code> prevents malformed coordinates, null byte injections, and empty paths from breaching the analyzer hull.</li>
</ul>
<h2>Code</h2>
<h3>packages/core/src/analyzer/repo-analyzer.ts</h3>
<pre><code class="language-typescript">async generateRepomixContext(projectPath: string, options: RepomixOptions = {}): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);
  
  // Check if adventure.config.json has specific files to include
  const configuredFiles = extractUniqueFilePaths(projectPath);
  
  if (configuredFiles.length &gt; 0) {
    // Use configured files with optimized content generation
    console.log(`Using adventure.config.json: analyzing ${configuredFiles.length} configured files with optimization`);
    try {
      return await this.generateOptimizedContent(projectPath, configuredFiles);
    } catch (error) {
      console.warn(`Failed to generate optimized content, falling back to targeted content: ${error instanceof Error ? error.message : String(error)}`);
      try {
        return await this.generateTargetedContent(projectPath, configuredFiles);
      } catch (fallbackError) {
        console.warn(`Failed to generate targeted content, falling back to full repomix content: ${fallbackError instanceof Error ? fallbackError.message : String(fallbackError)}`);
        // Fall through to full content generation
      }
    }
  }
  
  // Fallback: use existing behavior with all files (compressed)
  console.log(&#39;No adventure.config.json found: analyzing full codebase (compressed)&#39;);
  
  // Create cache key from path and options
  const cacheKey = `${path.resolve(projectPath)}:${JSON.stringify(options)}`;
  
  // Check cache first
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }
  
  
  try {
    // Build ignore patterns
    const ignorePatterns = [
      &#39;node_modules&#39;, &#39;dist&#39;, &#39;build&#39;, &#39;.git&#39;, &#39;coverage&#39;, &#39;.nyc_output&#39;
    ];
    
    if (!options.includeTests) {
      ignorePatterns.push(&#39;**/*.test.ts&#39;, &#39;**/*.spec.ts&#39;, &#39;**/tests/**&#39;, &#39;**/test/**&#39;);
    }

    // Configure repomix options
    const cliOptions: CliOptions = {
      style: options.style || &#39;markdown&#39;,
      stdout: true,
      compress: options.compress !== false, // Default to true unless explicitly disabled
      ignore: ignorePatterns.join(&#39;,&#39;),
      removeComments: true,
      removeEmptyLines: true,
      noDirectoryStructure: true
    };

    // Capture stdout during repomix execution
    const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
    
    // Cache the result
    this.cache.set(cacheKey, { content: context, timestamp: Date.now() });
    
    return context;
  } catch (error) {
    throw new Error(`Repomix execution failed: ${error instanceof Error ? error.message : String(error)}`);
  }
}
</code></pre>
<ul>
<li>Orchestrates the main scan path, choosing between configured, targeted, or full scans based on <code class="inline-code">adventure.config.json</code>.</li>
<li>Uses a cache keyed by absolute path plus options, conserving reactor cycles on repeated runs.</li>
<li>Applies ignore patterns to avoid noisy sectors and shrink the token payload via compression.</li>
<li>Delegates execution to <code class="inline-code">captureRepomixStdout</code>, isolating subprocess concerns in a single propulsion unit.</li>
<li>Provides layered fallbacks and warnings to maintain resilience when optimization or targeting fails.</li>
</ul>
<hr>
<pre><code class="language-typescript">async generateTargetedContent(projectPath: string, targetFiles: string[], compress: boolean = true): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);
  
  if (!targetFiles || targetFiles.length === 0) {
    throw new Error(&#39;Target files array cannot be empty&#39;);
  }
  
  // Harden and validate target files
  const safeFiles = this.validateAndNormalizeTargetFiles(projectPath, targetFiles);
  if (safeFiles.length === 0) {
    throw new Error(&#39;No valid target files found after validation&#39;);
  }
  
  // Create stable cache key from normalized files
  const cacheKey = `${path.resolve(projectPath)}:targeted:${safeFiles.join(&#39;,&#39;)}:compress=${compress}`;
  
  // Check cache first
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }
  
  
  try {
    // Configure repomix options for targeted extraction
    const cliOptions: CliOptions = {
      style: &#39;markdown&#39;,
      stdout: true,
      compress: compress, // Configurable compression
      include: safeFiles.join(&#39;,&#39;), // Only include validated files
      removeComments: compress, // Remove comments if compressing
      removeEmptyLines: compress, // Remove empty lines if compressing
      noDirectoryStructure: true
    };

    // Capture stdout during repomix execution
    const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
    
    // Cache the result
    this.cache.set(cacheKey, { content: context, timestamp: Date.now() });
    
    return context;
  } catch (error) {
    throw new Error(`Targeted repomix execution failed: ${error instanceof Error ? error.message : String(error)}`);
  }
}
</code></pre>
<ul>
<li>Focuses the scanner on a bounded set of files after validation and normalization.</li>
<li>Builds deterministic cache keys from sorted, safe paths to ensure repeatable signal retrieval.</li>
<li>Tunes compression flags to trade verbosity for token efficiency during transmission.</li>
<li>Encodes includes as a comma-joined list matching Repomix CLI expectations for precise constellation slices.</li>
<li>Surfaces targeted errors distinctly, making diagnosis of selection issues straightforward.</li>
</ul>
<hr>
<pre><code class="language-typescript">private async captureRepomixStdout(directories: string[], cwd: string, options: CliOptions): Promise&lt;string&gt; {
  return new Promise((resolve, reject) =&gt; {
    // Build repomix CLI arguments
    const args = [
      ...directories,
      &#39;--stdout&#39;,
      &#39;--style&#39;, options.style || &#39;markdown&#39;
    ];
    
    if (options.compress) args.push(&#39;--compress&#39;);
    if (options.removeComments) args.push(&#39;--remove-comments&#39;);
    if (options.removeEmptyLines) args.push(&#39;--remove-empty-lines&#39;);
    if (options.noDirectoryStructure) args.push(&#39;--no-directory-structure&#39;);
    if (options.ignore) args.push(&#39;--ignore&#39;, options.ignore);
    if (options.include) args.push(&#39;--include&#39;, options.include);
    
    // Spawn repomix as subprocess
    const repomix = spawn(&#39;npx&#39;, [&#39;repomix&#39;, ...args], {
      cwd,
      stdio: [&#39;pipe&#39;, &#39;pipe&#39;, &#39;pipe&#39;]
    });
    
    let stdout = &#39;&#39;;
    let stderr = &#39;&#39;;
    let stdoutSize = 0;
    let isResolved = false;
    
    // Set up timeout with graceful then force kill
    const timeout = setTimeout(() =&gt; {
      if (!isResolved) {
        console.warn(`Repomix subprocess timeout (${REPOMIX_SUBPROCESS_TIMEOUT}ms), killing process...`);
        repomix.kill(&#39;SIGTERM&#39;);
        setTimeout(() =&gt; repomix.kill(&#39;SIGKILL&#39;), REPOMIX_GRACEFUL_TIMEOUT);
        isResolved = true;
        reject(new Error(`Repomix subprocess timed out after ${REPOMIX_SUBPROCESS_TIMEOUT}ms (${cwd})`));
      }
    }, REPOMIX_SUBPROCESS_TIMEOUT);
    
    repomix.stdout.on(&#39;data&#39;, (data) =&gt; {
      const chunk = data.toString();
      stdoutSize += chunk.length;
      
      // Memory protection
      if (stdoutSize &gt; REPOMIX_MAX_BUFFER_SIZE) {
        if (!isResolved) {
          isResolved = true;
          clearTimeout(timeout);
          repomix.kill(&#39;SIGKILL&#39;);
          reject(new Error(`Repomix output too large (${stdoutSize} bytes) for ${cwd}`));
        }
        return;
      }
      
      stdout += chunk;
    });
    
    repomix.stderr.on(&#39;data&#39;, (data) =&gt; {
      stderr += data.toString();
    });
    
    repomix.on(&#39;close&#39;, (code) =&gt; {
      if (!isResolved) {
        isResolved = true;
        clearTimeout(timeout);
        
        if (code === 0 &amp;&amp; stdout.trim().length &gt; 0) {
          resolve(stdout);
        } else {
          reject(new Error(`Repomix failed (exit ${code}): ${stderr.substring(0, 200)}`));
        }
      }
    });
    
    repomix.on(&#39;error&#39;, (error) =&gt; {
      if (!isResolved) {
        isResolved = true;
        clearTimeout(timeout);
        reject(new Error(`Repomix spawn failed: ${error.message}`));
      }
    });
  });
}
</code></pre>
<ul>
<li>Encapsulates subprocess launch and lifecycle, providing strict time and memory bounds to prevent runaway burns.</li>
<li>Converts CLI options into arguments, including compression, includes, ignores, and style for predictable telemetry shaping.</li>
<li>Applies a two-stage abort: graceful <code class="inline-code">SIGTERM</code> then failsafe <code class="inline-code">SIGKILL</code>, ensuring the bridge stays responsive.</li>
<li>Resolves only when the exit code is clean and output exists, filtering empty noise from the cosmic stream.</li>
<li>Emits concise errors truncated to 200 characters, balancing signal with readability.</li>
</ul>
<hr>
<pre><code class="language-typescript">private validateProjectPath(projectPath: string): void {
  if (!projectPath || typeof projectPath !== &#39;string&#39;) {
    throw new Error(&#39;Project path must be a non-empty string&#39;);
  }

  const trimmedPath = projectPath.trim();
  if (!trimmedPath) {
    throw new Error(&#39;Project path must be a non-empty string&#39;);
  }

  // Basic safety check for null bytes (can break file system operations)
  if (trimmedPath.includes(&#39;\0&#39;)) {
    throw new Error(&#39;Project path contains invalid null bytes&#39;);
  }
}
</code></pre>
<ul>
<li>Performs early hull checks on coordinates to avoid filesystem anomalies and subtle injection vectors.</li>
<li>Enforces non-empty strings after trimming to prevent accidental launches with blank targets.</li>
<li>Explicitly rejects null bytes, a common source of IO and path handling faults in navigation routines.</li>
<li>Centralizes validation logic so all analyzer entry points get consistent protection.</li>
<li>Keeps the check minimal yet purposeful, reducing overhead while stopping critical edge cases.</li>
</ul>
<hr>
<h3>packages/core/src/llm/llm-client.ts</h3>
<pre><code class="language-typescript">async generateResponse(prompt: string, options?: LLMRequestOptions): Promise&lt;LLMResponse&gt; {
  try {
    const requestParams = this.buildRequestParams(prompt, options);
    const completion = await this.executeRequest(requestParams);
    let content = this.validateResponse(completion);
    
    // Post-process JSON responses that might be wrapped in markdown
    if (options?.responseFormat === &#39;json_object&#39;) {
      content = this.cleanJsonResponse(content);
    }
    
    this.logTokenUsage(completion);
    
    return { content };
  } catch (error) {
    // Enhanced error logging for debugging
    this.logDetailedError(error, prompt);
    
    const message = error instanceof Error ? error.message : &#39;Unknown error&#39;;
    throw new Error(`LLM request failed: ${message}`);
  }
}
</code></pre>
<ul>
<li>Orchestrates the LLM signal leg: build parameters, race execution, validate payload, cleanse JSON wrappers, and report usage.</li>
<li>Wraps the operation in <code class="inline-code">try/catch</code> with rich diagnostics via <code class="inline-code">logDetailedError</code>, boosting observability during turbulence.</li>
<li>Defers param shaping to a builder, keeping this function focused on mission flow and post-processing.</li>
<li>Emits token telemetry for prompt and completion, aiding reactor budgeting across voyages.</li>
<li>Normalizes error shapes, ensuring callers receive consistent failure messages.</li>
</ul>
<hr>
<pre><code class="language-typescript">constructor() {
  this.model = LLM_MODEL;
  
  // Determine API key based on provider
  const apiKey = this.getApiKey();
  if (!apiKey || !LLM_BASE_URL) {
    throw new Error(&#39;LLM configuration required. Please set LLM_BASE_URL and appropriate API key (LLM_API_KEY or GITHUB_TOKEN).&#39;);
  }

  if (this.isAzureOpenAI()) {
    // Azure OpenAI requires endpoint without the path
    const azureEndpoint = LLM_BASE_URL.split(&#39;/openai/deployments&#39;)[0];
    this.client = new AzureOpenAI({
      endpoint: azureEndpoint,
      apiKey,
      apiVersion: LLM_API_VERSION,
      deployment: this.model
    });
  } else {
    this.client = new OpenAI({
      apiKey,
      baseURL: LLM_BASE_URL
    });
  }
}
</code></pre>
<ul>
<li>Initializes the comms array by selecting provider shape and deriving the correct client for Azure or standard OpenAI.</li>
<li>Validates that both base URL and a compatible API key are present before enabling the transmitter.</li>
<li>Adjusts Azure endpoints by trimming deployment paths, aligning with Azure‚Äôs expected topology.</li>
<li>Uses <code class="inline-code">LLM_MODEL</code> as the deployment identifier, centralizing model selection via config.</li>
<li>Encapsulates provider branching here, so the rest of the class can treat <code class="inline-code">this.client</code> uniformly.</li>
</ul>
<hr>
<pre><code class="language-typescript">private getApiKey(): string {
  // GitHub Models (hosted on Azure) uses GITHUB_TOKEN
  if (LLM_BASE_URL.includes(&#39;models.inference.ai.azure.com&#39;)) {
    if (!GITHUB_TOKEN) {
      throw new Error(&#39;GITHUB_TOKEN required for GitHub Models. Set GITHUB_TOKEN environment variable.&#39;);
    }
    return GITHUB_TOKEN;
  }
  // All other providers (OpenAI, Azure OpenAI, Ollama, etc.) use LLM_API_KEY
  if (!LLM_API_KEY) {
    throw new Error(&#39;LLM_API_KEY required. Set LLM_API_KEY environment variable.&#39;);
  }
  return LLM_API_KEY;
}
</code></pre>
<ul>
<li>Selects the appropriate credential lane based on host patterns, mapping GitHub Models to <code class="inline-code">GITHUB_TOKEN</code>.</li>
<li>Enforces presence of keys with explicit error messages, improving setup clarity for the crew.</li>
<li>Avoids ambiguity by segregating provider families with a simple host predicate.</li>
<li>Centralizes secret lookup, enabling consistent diagnostics and future expansion.</li>
<li>Keeps logic minimal and readable, reducing risk in a critical boot path.</li>
</ul>
<hr>
<pre><code class="language-typescript">private isAzureOpenAI(): boolean {
  return LLM_BASE_URL.includes(&#39;.openai.azure.com&#39;) || LLM_BASE_URL.includes(&#39;cognitiveservices.azure.com&#39;);
}
</code></pre>
<ul>
<li>Distinguishes Azure OpenAI endpoints by host fragments, guiding client instantiation logic.</li>
<li>Keeps the provider check cheap and deterministic with simple substring matches.</li>
<li>Unlocks correct parameter mapping and endpoint selection in the constructor.</li>
<li>Provides a single source of truth for Azure detection across diagnostics.</li>
<li>Enhances maintainability by avoiding scattered environment checks.</li>
</ul>
<h2>Helpful Hints</h2>
<ul>
<li>Use targeted extraction first to stabilize your scans; compression reduces token burn during long jumps.</li>
<li>Monitor timeouts and buffer sizes in <code class="inline-code">captureRepomixStdout</code> to diagnose stalled subprocess beacons.</li>
<li>Confirm your model and base URL pairing; mismatched credentials will ground the transmitter.</li>
</ul>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries.</p>
<p>Mission accomplished, cadet‚Äîyour Quest 3: Cosmic Signal Pipeline is locked onto the stars with crystal-clear telemetry, boosting you to 2/5 quests (40%) and igniting momentum for the next burn toward mastery‚Äîkeep that üì° online and prepare for the next ‚≠ê jump!</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-2.html" class="prev-quest-btn">‚Üê Previous: Quest 2</a>
        <a href="quest-4.html" class="next-quest-btn">Next: Quest 4 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="assets/quest-navigator.js"></script>
</body>
</html>