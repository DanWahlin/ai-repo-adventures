<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quest 3: Code Analysis & Content Pipeline - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="assets/quest-navigator.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }
        
        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body>

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="index.html">Chronicles of the Code Pyramid</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <a href="https://github.com/danwahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="assets/images/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 3: Code Analysis &amp; Content Pipeline</h1>
<hr>
<p>In the pyramid‚Äôs dim corridors, you enter the Chamber of Scrutiny where bronze mirrors reflect code like runes on obsidian. Here, the MCP antechamber is silent; instead, the Analysis Pipeline and Scribe LLM hum like hidden gears beneath the stone. Copper conduits feed repository scrolls into an interpretive engine, while another conduit whispers to a distant oracle that answers in structured lines. Study these carvings carefully: the repository capturer controls breadth, the stdout siphon resists floods and time, and the scribe client tames strange dialects and routes. Assemble their workings to align the expedition‚Äôs tools.</p>
<h2>Quest Objectives</h2>
<p>As you explore the code below, investigate these key questions:</p>
<ul>
<li>üîç Sand-table Patterns: How does <code class="inline-code">generateRepomixContext</code> decide between optimized, targeted, and full analysis when <code class="inline-code">adventure.config.json</code> influences file selection?</li>
<li>‚ö° Gate Timing Rituals: In what order do <code class="inline-code">generateTargetedContent</code> and <code class="inline-code">captureRepomixStdout</code> coordinate arguments and timeouts to prevent runaway subprocesses?</li>
<li>üõ°Ô∏è Ward of Boundaries: How does <code class="inline-code">validateProjectPath</code> guard against malformed paths, and how does <code class="inline-code">LLMClient.getApiKey</code> enforce provider-specific credentials without ambiguity?</li>
<li>üîç Oracle Dialects: How does <code class="inline-code">LLMClient.constructor</code> distinguish Azure routing from generic paths, and what configuration fragments drive deployment selection?</li>
<li>üõ°Ô∏è Echo Purification: When <code class="inline-code">LLMClient.generateResponse</code> encounters empty or markdown-wrapped content, which safeguards and cleaners ensure stable, usable answers?</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">packages/core/src/analyzer/repo-analyzer.ts:</span> The repository scribe that gathers scrolls into a single curated codex</h3>
<p>Within these stone lines, <code class="inline-code">RepoAnalyzer</code> orchestrates how repository content is captured from the jungle of files and funneled into a portable context. The path is validated by <code class="inline-code">validateProjectPath</code> to prevent hazardous traversal and malformed inputs. When <code class="inline-code">generateRepomixContext</code> is invoked, it first consults <code class="inline-code">adventure.config.json</code> via <code class="inline-code">extractUniqueFilePaths</code>, attempting an optimized route that filters for meaningful function bodies. If that falters, it cascades to targeted extraction, then to a comprehensive scan with compression and ignores. The heart of the capture is <code class="inline-code">captureRepomixStdout</code>, which spawns <code class="inline-code">repomix</code> as a subprocess, enforcing a timeout talisman and memory wards: it trims outputs that grow beyond <code class="inline-code">REPOMIX_MAX_BUFFER_SIZE</code> and kills the process if it lingers beyond <code class="inline-code">REPOMIX_SUBPROCESS_TIMEOUT</code>, applying a graceful window before a hard stop. <code class="inline-code">generateTargetedContent</code> composes CLI options, limiting scope with <code class="inline-code">include</code> and tuning compression and comment removal, caching results keyed by path and options to spare repeated journeys. Together, these rituals ensure reliable, bounded, and token-efficient content suitable for downstream analysis and storytelling, binding raw code into a structured ledger fit for a learned expedition.</p>
<h4>Highlights</h4>
<ul>
<li><code class="inline-code">generateRepomixContext</code> chooses between optimized, targeted, and full scans, caching by project and options; this orchestrates breadth and performance.</li>
<li><code class="inline-code">generateTargetedContent</code> composes precise <code class="inline-code">repomix</code> CLI flags for selected files, ensuring token thrift and stable cache keys.</li>
<li><code class="inline-code">captureRepomixStdout</code> spawns <code class="inline-code">repomix</code> with strict time and size controls, resolving only on healthy exit, which stabilizes long expeditions.</li>
<li><code class="inline-code">validateProjectPath</code> enforces basic path integrity, rejecting null bytes and emptiness to prevent missteps at the chamber threshold.</li>
</ul>
<h2>Code</h2>
<h3>packages/core/src/analyzer/repo-analyzer.ts</h3>
<pre><code class="language-typescript">async generateRepomixContext(projectPath: string, options: RepomixOptions = {}): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);
  
  // Check if adventure.config.json has specific files to include
  const configuredFiles = extractUniqueFilePaths(projectPath);
  
  if (configuredFiles.length &gt; 0) {
    // Use configured files with optimized content generation
    console.log(`Using adventure.config.json: analyzing ${configuredFiles.length} configured files with optimization`);
    try {
      return await this.generateOptimizedContent(projectPath, configuredFiles);
    } catch (error) {
      console.warn(`Failed to generate optimized content, falling back to targeted content: ${error instanceof Error ? error.message : String(error)}`);
      try {
        return await this.generateTargetedContent(projectPath, configuredFiles);
      } catch (fallbackError) {
        console.warn(`Failed to generate targeted content, falling back to full repomix content: ${fallbackError instanceof Error ? fallbackError.message : String(fallbackError)}`);
        // Fall through to full content generation
      }
    }
  }
  
  // Fallback: use existing behavior with all files (compressed)
  console.log(&#39;No adventure.config.json found: analyzing full codebase (compressed)&#39;);
  
  // Create cache key from path and options
  const cacheKey = `${path.resolve(projectPath)}:${JSON.stringify(options)}`;
  
  // Check cache first
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }
  
  
  try {
    // Build ignore patterns
    const ignorePatterns = [
      &#39;node_modules&#39;, &#39;dist&#39;, &#39;build&#39;, &#39;.git&#39;, &#39;coverage&#39;, &#39;.nyc_output&#39;
    ];
    
    if (!options.includeTests) {
      ignorePatterns.push(&#39;**/*.test.ts&#39;, &#39;**/*.spec.ts&#39;, &#39;**/tests/**&#39;, &#39;**/test/**&#39;);
    }

    // Configure repomix options
    const cliOptions: CliOptions = {
      style: options.style || &#39;markdown&#39;,
      stdout: true,
      compress: options.compress !== false, // Default to true unless explicitly disabled
      ignore: ignorePatterns.join(&#39;,&#39;),
      removeComments: true,
      removeEmptyLines: true,
      noDirectoryStructure: true
    };

    // Capture stdout during repomix execution
    const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
    
    // Cache the result
    this.cache.set(cacheKey, { content: context, timestamp: Date.now() });
    
    return context;
  } catch (error) {
    throw new Error(`Repomix execution failed: ${error instanceof Error ? error.message : String(error)}`);
  }
}
</code></pre>
<ul>
<li>This code governs the main flow for building repository context, preferring configured, optimized paths before full scans.</li>
<li>It demonstrates cascading fallbacks that preserve robustness under failure while logging useful waypoints.</li>
<li>Cache keys combine absolute path and serialized options to avoid collisions and redundant work.</li>
<li>Ignore patterns and compression flags constrain noise and shrink output for token efficiency.</li>
<li>It connects to <code class="inline-code">captureRepomixStdout</code> as the final step, delegating subprocess orchestration.</li>
</ul>
<hr>
<pre><code class="language-typescript">async generateTargetedContent(projectPath: string, targetFiles: string[], compress: boolean = true): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);
  
  if (!targetFiles || targetFiles.length === 0) {
    throw new Error(&#39;Target files array cannot be empty&#39;);
  }
  
  // Harden and validate target files
  const safeFiles = this.validateAndNormalizeTargetFiles(projectPath, targetFiles);
  if (safeFiles.length === 0) {
    throw new Error(&#39;No valid target files found after validation&#39;);
  }
  
  // Create stable cache key from normalized files
  const cacheKey = `${path.resolve(projectPath)}:targeted:${safeFiles.join(&#39;,&#39;)}:compress=${compress}`;
  
  // Check cache first
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }
  
  
  try {
    // Configure repomix options for targeted extraction
    const cliOptions: CliOptions = {
      style: &#39;markdown&#39;,
      stdout: true,
      compress: compress, // Configurable compression
      include: safeFiles.join(&#39;,&#39;), // Only include validated files
      removeComments: compress, // Remove comments if compressing
      removeEmptyLines: compress, // Remove empty lines if compressing
      noDirectoryStructure: true
    };

    // Capture stdout during repomix execution
    const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
    
    // Cache the result
    this.cache.set(cacheKey, { content: context, timestamp: Date.now() });
    
    return context;
  } catch (error) {
    throw new Error(`Targeted repomix execution failed: ${error instanceof Error ? error.message : String(error)}`);
  }
}
</code></pre>
<ul>
<li>Focuses on selective file extraction, using validation and normalization to enforce boundaries and reliability.</li>
<li>Builds deterministic cache keys from sorted safe files and compression choice to maximize reuse.</li>
<li>Applies compression-driven flags to reduce token load by stripping comments and empty lines.</li>
<li>Delegates execution to <code class="inline-code">captureRepomixStdout</code>, keeping concerns separated between configuration and process control.</li>
<li>Errors are wrapped with clear context for easier debugging along the expedition path.</li>
</ul>
<hr>
<pre><code class="language-typescript">private async captureRepomixStdout(directories: string[], cwd: string, options: CliOptions): Promise&lt;string&gt; {
  return new Promise((resolve, reject) =&gt; {
    // Build repomix CLI arguments
    const args = [
      ...directories,
      &#39;--stdout&#39;,
      &#39;--style&#39;, options.style || &#39;markdown&#39;
    ];
    
    if (options.compress) args.push(&#39;--compress&#39;);
    if (options.removeComments) args.push(&#39;--remove-comments&#39;);
    if (options.removeEmptyLines) args.push(&#39;--remove-empty-lines&#39;);
    if (options.noDirectoryStructure) args.push(&#39;--no-directory-structure&#39;);
    if (options.ignore) args.push(&#39;--ignore&#39;, options.ignore);
    if (options.include) args.push(&#39;--include&#39;, options.include);
    
    // Spawn repomix as subprocess
    const repomix = spawn(&#39;npx&#39;, [&#39;repomix&#39;, ...args], {
      cwd,
      stdio: [&#39;pipe&#39;, &#39;pipe&#39;, &#39;pipe&#39;]
    });
    
    let stdout = &#39;&#39;;
    let stderr = &#39;&#39;;
    let stdoutSize = 0;
    let isResolved = false;
    
    // Set up timeout with graceful then force kill
    const timeout = setTimeout(() =&gt; {
      if (!isResolved) {
        console.warn(`Repomix subprocess timeout (${REPOMIX_SUBPROCESS_TIMEOUT}ms), killing process...`);
        repomix.kill(&#39;SIGTERM&#39;);
        setTimeout(() =&gt; repomix.kill(&#39;SIGKILL&#39;), REPOMIX_GRACEFUL_TIMEOUT);
        isResolved = true;
        reject(new Error(`Repomix subprocess timed out after ${REPOMIX_SUBPROCESS_TIMEOUT}ms (${cwd})`));
      }
    }, REPOMIX_SUBPROCESS_TIMEOUT);
    
    repomix.stdout.on(&#39;data&#39;, (data) =&gt; {
      const chunk = data.toString();
      stdoutSize += chunk.length;
      
      // Memory protection
      if (stdoutSize &gt; REPOMIX_MAX_BUFFER_SIZE) {
        if (!isResolved) {
          isResolved = true;
          clearTimeout(timeout);
          repomix.kill(&#39;SIGKILL&#39;);
          reject(new Error(`Repomix output too large (${stdoutSize} bytes) for ${cwd}`));
        }
        return;
      }
      
      stdout += chunk;
    });
    
    repomix.stderr.on(&#39;data&#39;, (data) =&gt; {
      stderr += data.toString();
    });
    
    repomix.on(&#39;close&#39;, (code) =&gt; {
      if (!isResolved) {
        isResolved = true;
        clearTimeout(timeout);
        
        if (code === 0 &amp;&amp; stdout.trim().length &gt; 0) {
          resolve(stdout);
        } else {
          reject(new Error(`Repomix failed (exit ${code}): ${stderr.substring(0, 200)}`));
        }
      }
    });
    
    repomix.on(&#39;error&#39;, (error) =&gt; {
      if (!isResolved) {
        isResolved = true;
        clearTimeout(timeout);
        reject(new Error(`Repomix spawn failed: ${error.message}`));
      }
    });
  });
}
</code></pre>
<ul>
<li>Implements strict subprocess control with dual-phase termination: graceful <code class="inline-code">SIGTERM</code> then forced <code class="inline-code">SIGKILL</code>.</li>
<li>Enforces an output size ceiling to prevent memory overflows during long harvests from large code jungles.</li>
<li>Assembles CLI flags dynamically from options, keeping a single construction path for consistency.</li>
<li>Resolves only on successful exit with non-empty stdout; else emits concise diagnostics for quick triage.</li>
<li>Encapsulates subprocess behavior to keep higher-level methods focused on selection and caching.</li>
</ul>
<hr>
<pre><code class="language-typescript">private validateProjectPath(projectPath: string): void {
  if (!projectPath || typeof projectPath !== &#39;string&#39;) {
    throw new Error(&#39;Project path must be a non-empty string&#39;);
  }

  const trimmedPath = projectPath.trim();
  if (!trimmedPath) {
    throw new Error(&#39;Project path must be a non-empty string&#39;);
  }

  // Basic safety check for null bytes (can break file system operations)
  if (trimmedPath.includes(&#39;\0&#39;)) {
    throw new Error(&#39;Project path contains invalid null bytes&#39;);
  }
}
</code></pre>
<ul>
<li>Guards the chamber entrance by rejecting empty, non-string, and null-byte-tainted inputs.</li>
<li>Keeps validation intentionally minimal and fast while preventing hazardous edge cases.</li>
<li>Centralizes checks so all upstream capture routines benefit from uniform protection.</li>
<li>Reduces risk of filesystem anomalies that could derail the toolchain.</li>
<li>Sets a consistent precondition for the entire analysis flow.</li>
</ul>
<hr>
<h3>packages/core/src/llm/llm-client.ts</h3>
<pre><code class="language-typescript">constructor() {
  this.model = LLM_MODEL;
  
  // Determine API key based on provider
  const apiKey = this.getApiKey();
  if (!apiKey || !LLM_BASE_URL) {
    throw new Error(&#39;LLM configuration required. Please set LLM_BASE_URL and appropriate API key (LLM_API_KEY or GITHUB_TOKEN).&#39;);
  }

  if (this.isAzureOpenAI()) {
    // Azure OpenAI requires endpoint without the path
    const azureEndpoint = LLM_BASE_URL.split(&#39;/openai/deployments&#39;)[0];
    this.client = new AzureOpenAI({
      endpoint: azureEndpoint,
      apiKey,
      apiVersion: LLM_API_VERSION,
      deployment: this.model
    });
  } else {
    this.client = new OpenAI({
      apiKey,
      baseURL: LLM_BASE_URL
    });
  }
}
</code></pre>
<ul>
<li>Initializes the oracle client, branching to <code class="inline-code">AzureOpenAI</code> when the base URL matches Azure patterns.</li>
<li>Requires both base URL and a valid API key, failing fast with a clear message when missing.</li>
<li>For Azure, trims the deployment path and passes <code class="inline-code">deployment</code> and <code class="inline-code">apiVersion</code>, aligning with platform constraints.</li>
<li>For non-Azure, configures generic <code class="inline-code">OpenAI</code> with <code class="inline-code">baseURL</code> to support custom gateways.</li>
<li>Encodes provider selection logic into readable guards for predictable behavior.</li>
</ul>
<hr>
<pre><code class="language-typescript">private getApiKey(): string {
  // GitHub Models (hosted on Azure) uses GITHUB_TOKEN
  if (LLM_BASE_URL.includes(&#39;models.inference.ai.azure.com&#39;)) {
    if (!GITHUB_TOKEN) {
      throw new Error(&#39;GITHUB_TOKEN required for GitHub Models. Set GITHUB_TOKEN environment variable.&#39;);
    }
    return GITHUB_TOKEN;
  }
  // All other providers (OpenAI, Azure OpenAI, Ollama, etc.) use LLM_API_KEY
  if (!LLM_API_KEY) {
    throw new Error(&#39;LLM_API_KEY required. Set LLM_API_KEY environment variable.&#39;);
  }
  return LLM_API_KEY;
}
</code></pre>
<ul>
<li>Distinguishes GitHub Models routing via URL pattern, enforcing <code class="inline-code">GITHUB_TOKEN</code> specifically.</li>
<li>Defaults all other providers to <code class="inline-code">LLM_API_KEY</code>, providing a single source of truth for credentials.</li>
<li>Fails with precise guidance to reduce configuration guesswork in the field.</li>
<li>Encapsulates provider heuristics, so callers remain clean and provider-agnostic.</li>
<li>Supports secure, explicit token selection that avoids silent misconfiguration.</li>
</ul>
<hr>
<pre><code class="language-typescript">private isAzureOpenAI(): boolean {
  return LLM_BASE_URL.includes(&#39;.openai.azure.com&#39;) || LLM_BASE_URL.includes(&#39;cognitiveservices.azure.com&#39;);
}
</code></pre>
<ul>
<li>Detects Azure endpoints by checking known host fragments.</li>
<li>Keeps decision logic straightforward and fast, avoiding brittle parsing.</li>
<li>Serves as a compact rune used by the constructor to choose the correct client.</li>
<li>Reduces branching complexity elsewhere by isolating endpoint checks.</li>
<li>Enhances maintainability when new Azure host patterns appear.</li>
</ul>
<hr>
<pre><code class="language-typescript">async generateResponse(prompt: string, options?: LLMRequestOptions): Promise&lt;LLMResponse&gt; {
  try {
    const requestParams = this.buildRequestParams(prompt, options);
    const completion = await this.executeRequest(requestParams);
    let content = this.validateResponse(completion);
    
    // Post-process JSON responses that might be wrapped in markdown
    if (options?.responseFormat === &#39;json_object&#39;) {
      content = this.cleanJsonResponse(content);
    }
    
    this.logTokenUsage(completion);
    
    return { content };
  } catch (error) {
    // Enhanced error logging for debugging
    this.logDetailedError(error, prompt);
    
    const message = error instanceof Error ? error.message : &#39;Unknown error&#39;;
    throw new Error(`LLM request failed: ${message}`);
  }
}
</code></pre>
<ul>
<li>Drives end-to-end response generation: build parameters, execute, validate, clean, and log usage.</li>
<li>Applies a JSON unwrapping step to extract payloads from markdown code fences, ensuring stable downstream parsing.</li>
<li>Wraps failures with detailed diagnostics to illuminate configuration, routing, and timeout causes.</li>
<li>Centralizes success and failure paths, making the oracle‚Äôs behavior predictable and observable.</li>
<li>Connects to multiple internal helpers to keep logic modular and testable.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Trace cache keys carefully; consistent normalization prevents accidental cache misses during repeated rites.</li>
<li>Compare <code class="inline-code">compress</code> settings with your token budget; comment removal can conserve precious context for the scribe.</li>
<li>For LLM routing, verify <code class="inline-code">LLM_BASE_URL</code> early; a small mismatch can lead you into side tunnels that never answer.</li>
</ul>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries.</p>
<p>By the sacred fires of the code-temple, thou hast deciphered the runes of analysis and forged a steadfast content pipeline‚Äîa triumphant step (Quest 3 complete, 2/5 quests, 40% ascended) upon the wisdom-road to mastery, let the oracle‚Äôs gong resound as you advance with valor and clarity.</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-2.html" class="prev-quest-btn">‚Üê Previous: Quest 2</a>
        <a href="quest-4.html" class="next-quest-btn">Next: Quest 4 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="assets/quest-navigator.js"></script>
</body>
</html>