<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quest 3: Code Analysis & Content Pipeline - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="assets/quest-navigator.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }
        
        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body>

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="index.html">The Enchanted Repository of Living Quests</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <a href="https://github.com/danwahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="assets/images/github-mark.svg" alt="GitHub" width="24" height="24">
                </a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 3: Code Analysis &amp; Content Pipeline</h1>
<hr>
<p>Across the citadel of computation, you step onto a balcony of runes where scrolls whisper of sources and sockets. The <code class="inline-code">RepoAnalyzer</code> is a map-making sage, distilling vast forests of files into clear, travel-ready charts. In a tower of crystal circuits, the <code class="inline-code">LLMClient</code> channels arcane counsel with careful wards, binding models, keys, and time. These are exploration guides, not prerequisites: let your eyes trace sigils, follow flows, and unveil patterns that govern this enchanted pipeline of knowledge.</p>
<h2>Quest Objectives</h2>
<p>As you explore the code below, investigate these key questions:</p>
<ul>
<li>üîç Scribe‚Äôs Compass: How does <code class="inline-code">generateTargetedContent</code> constrain and sanitize target paths to prevent traversal and ensure stable caching keys?</li>
<li>‚ö° Chronomancer‚Äôs Ward: In <code class="inline-code">LLMClient.generateResponse</code>, where is timeout protection enacted and how is it integrated into the request flow?</li>
<li>üõ°Ô∏è Gate of Provenance: What safety checks does <code class="inline-code">validateProjectPath</code> enforce, and how do they influence downstream operations?</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">packages/core/src/analyzer/repo-analyzer.ts:</span> The cartographer-sage that summons curated code context</h3>
<p>This sage gathers code lore using guarded rituals. The <code class="inline-code">validateProjectPath</code> spell ensures the journey begins on solid ground by confirming non-empty strings and detecting null-byte trickery. From there, <code class="inline-code">generateTargetedContent</code> invokes path sanctification through a private gauntlet, limiting the number of targets, rejecting traversal, and confirming existence. It crafts a deterministic cache key with normalized, sorted paths and the <code class="inline-code">compress</code> flag, then delegates to <code class="inline-code">captureRepomixStdout</code>, a controlled summoning of the Repomix familiar. That subprocess is bound by twin binds: a hard time leash via <code class="inline-code">REPOMIX_SUBPROCESS_TIMEOUT</code> with a graceful <code class="inline-code">SIGTERM</code> followed by <code class="inline-code">SIGKILL</code>, and a memory ward using <code class="inline-code">REPOMIX_MAX_BUFFER_SIZE</code>. If Repomix sings success, the content is cached, accelerating future pilgrimages within <code class="inline-code">REPOMIX_CACHE_TTL</code>. These rites form a safe, repeatable ritual that converts sprawling repositories into concise, targeted manuscripts, ensuring integrity, performance, and reproducibility throughout the adventure.</p>
<h4>Highlights</h4>
<ul>
<li><code class="inline-code">validateProjectPath</code> validates input paths to prevent malformed or hazardous beginnings, crucial for all downstream file operations.</li>
<li><code class="inline-code">generateTargetedContent</code> orchestrates targeted extraction with caching, normalization, and secure inclusion rules, ensuring deterministic and safe content gathering.</li>
<li><code class="inline-code">captureRepomixStdout</code> launches and supervises the Repomix subprocess, enforcing time and memory protections for reliability and stability.</li>
</ul>
<h2>Code</h2>
<h3>packages/core/src/analyzer/repo-analyzer.ts</h3>
<pre><code class="language-typescript">  private validateProjectPath(projectPath: string): void {
    if (!projectPath || typeof projectPath !== &#39;string&#39;) {
      throw new Error(&#39;Project path must be a non-empty string&#39;);
    }

    const trimmedPath = projectPath.trim();
    if (!trimmedPath) {
      throw new Error(&#39;Project path must be a non-empty string&#39;);
    }

    // Basic safety check for null bytes (can break file system operations)
    if (trimmedPath.includes(&#39;\0&#39;)) {
      throw new Error(&#39;Project path contains invalid null bytes&#39;);
    }
  }
</code></pre>
<ul>
<li>Ensures <code class="inline-code">projectPath</code> is a non-empty <code class="inline-code">string</code>, blocking undefined, non-strings, and whitespace-only inputs.</li>
<li>Guards against null-byte injection, a classic filesystem hazard.</li>
<li>Provides fast-failing validation to prevent wasted downstream work and hard-to-debug subprocess errors.</li>
<li>Centralizes path sanity checks to simplify reasoning in higher-level methods like <code class="inline-code">generateTargetedContent</code>.</li>
<li>Establishes a consistent contract for all path consumers in the analyzer.</li>
</ul>
<hr>
<pre><code class="language-typescript">  async generateTargetedContent(projectPath: string, targetFiles: string[], compress: boolean = true): Promise&lt;string&gt; {
    this.validateProjectPath(projectPath);
    
    if (!targetFiles || targetFiles.length === 0) {
      throw new Error(&#39;Target files array cannot be empty&#39;);
    }
    
    // Harden and validate target files
    const safeFiles = this.validateAndNormalizeTargetFiles(projectPath, targetFiles);
    if (safeFiles.length === 0) {
      throw new Error(&#39;No valid target files found after validation&#39;);
    }
    
    // Create stable cache key from normalized files
    const cacheKey = `${path.resolve(projectPath)}:targeted:${safeFiles.join(&#39;,&#39;)}:compress=${compress}`;
    
    // Check cache first
    const cached = this.cache.get(cacheKey);
    if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
      return cached.content;
    }
    
    
    try {
      // Configure repomix options for targeted extraction
      const cliOptions: CliOptions = {
        style: &#39;markdown&#39;,
        stdout: true,
        compress: compress, // Configurable compression
        include: safeFiles.join(&#39;,&#39;), // Only include validated files
        removeComments: compress, // Remove comments if compressing
        removeEmptyLines: compress, // Remove empty lines if compressing
        noDirectoryStructure: true
      };

      // Capture stdout during repomix execution
      const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
      
      // Cache the result
      this.cache.set(cacheKey, { content: context, timestamp: Date.now() });
      
      return context;
    } catch (error) {
      throw new Error(`Targeted repomix execution failed: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
</code></pre>
<ul>
<li>Validates inputs, normalizes and reduces <code class="inline-code">targetFiles</code> to a secure, sorted list, then builds a deterministic cache key.</li>
<li>Uses <code class="inline-code">REPOMIX_CACHE_TTL</code> to avoid redundant subprocess calls, improving performance for repeated queries.</li>
<li>Constructs precise <code class="inline-code">CliOptions</code>, set to include only validated files and optionally compress output to manage token budgets.</li>
<li>Calls <code class="inline-code">captureRepomixStdout</code> to safely run Repomix and retrieves exactly scoped context.</li>
<li>Catches and wraps errors with actionable diagnostics for callers.</li>
</ul>
<hr>
<pre><code class="language-typescript">  private async captureRepomixStdout(directories: string[], cwd: string, options: CliOptions): Promise&lt;string&gt; {
    return new Promise((resolve, reject) =&gt; {
      // Build repomix CLI arguments
      const args = [
        ...directories,
        &#39;--stdout&#39;,
        &#39;--style&#39;, options.style || &#39;markdown&#39;
      ];
      
      if (options.compress) args.push(&#39;--compress&#39;);
      if (options.removeComments) args.push(&#39;--remove-comments&#39;);
      if (options.removeEmptyLines) args.push(&#39;--remove-empty-lines&#39;);
      if (options.noDirectoryStructure) args.push(&#39;--no-directory-structure&#39;);
      if (options.ignore) args.push(&#39;--ignore&#39;, options.ignore);
      if (options.include) args.push(&#39;--include&#39;, options.include);
      
      // Spawn repomix as subprocess
      const repomix = spawn(&#39;npx&#39;, [&#39;repomix&#39;, ...args], {
        cwd,
        stdio: [&#39;pipe&#39;, &#39;pipe&#39;, &#39;pipe&#39;]
      });
      
      let stdout = &#39;&#39;;
      let stderr = &#39;&#39;;
      let stdoutSize = 0;
      let isResolved = false;
      
      // Set up timeout with graceful then force kill
      const timeout = setTimeout(() =&gt; {
        if (!isResolved) {
          console.warn(`Repomix subprocess timeout (${REPOMIX_SUBPROCESS_TIMEOUT}ms), killing process...`);
          repomix.kill(&#39;SIGTERM&#39;);
          setTimeout(() =&gt; repomix.kill(&#39;SIGKILL&#39;), REPOMIX_GRACEFUL_TIMEOUT);
          isResolved = true;
          reject(new Error(`Repomix subprocess timed out after ${REPOMIX_SUBPROCESS_TIMEOUT}ms (${cwd})`));
        }
      }, REPOMIX_SUBPROCESS_TIMEOUT);
      
      repomix.stdout.on(&#39;data&#39;, (data) =&gt; {
        const chunk = data.toString();
        stdoutSize += chunk.length;
        
        // Memory protection
        if (stdoutSize &gt; REPOMIX_MAX_BUFFER_SIZE) {
          if (!isResolved) {
            isResolved = true;
            clearTimeout(timeout);
            repomix.kill(&#39;SIGKILL&#39;);
            reject(new Error(`Repomix output too large (${stdoutSize} bytes) for ${cwd}`));
          }
          return;
        }
        
        stdout += chunk;
      });
      
      repomix.stderr.on(&#39;data&#39;, (data) =&gt; {
        stderr += data.toString();
      });
      
      repomix.on(&#39;close&#39;, (code) =&gt; {
        if (!isResolved) {
          isResolved = true;
          clearTimeout(timeout);
          
          if (code === 0 &amp;&amp; stdout.trim().length &gt; 0) {
            resolve(stdout);
          } else {
            reject(new Error(`Repomix failed (exit ${code}): ${stderr.substring(0, 200)}`));
          }
        }
      });
      
      repomix.on(&#39;error&#39;, (error) =&gt; {
        if (!isResolved) {
          isResolved = true;
          clearTimeout(timeout);
          reject(new Error(`Repomix spawn failed: ${error.message}`));
        }
      });
    });
  }
</code></pre>
<ul>
<li>Supervises a subprocess with a two-stage timeout: graceful <code class="inline-code">SIGTERM</code>, then forced <code class="inline-code">SIGKILL</code>, using <code class="inline-code">REPOMIX_SUBPROCESS_TIMEOUT</code> and <code class="inline-code">REPOMIX_GRACEFUL_TIMEOUT</code>.</li>
<li>Enforces <code class="inline-code">REPOMIX_MAX_BUFFER_SIZE</code> to prevent memory exhaustion attacks or runaway output.</li>
<li>Streams stdout with incremental size accounting, buffering safely until completion.</li>
<li>Provides clear error channels: spawn errors, timeouts, exit-code failures, and oversized outputs.</li>
<li>Ensures deterministic resolution with an <code class="inline-code">isResolved</code> sentinel to avoid double callbacks.</li>
</ul>
<hr>
<h3>packages/core/src/llm/llm-client.ts</h3>
<pre><code class="language-typescript">  constructor() {
    this.model = LLM_MODEL;
    
    // Determine API key based on provider
    const apiKey = this.getApiKey();
    if (!apiKey || !LLM_BASE_URL) {
      throw new Error(&#39;LLM configuration required. Please set LLM_BASE_URL and appropriate API key (LLM_API_KEY or GITHUB_TOKEN).&#39;);
    }

    if (this.isAzureOpenAI()) {
      // Azure OpenAI requires endpoint without the path
      const azureEndpoint = LLM_BASE_URL.split(&#39;/openai/deployments&#39;)[0];
      this.client = new AzureOpenAI({
        endpoint: azureEndpoint,
        apiKey,
        apiVersion: LLM_API_VERSION,
        deployment: this.model
      });
    } else {
      this.client = new OpenAI({
        apiKey,
        baseURL: LLM_BASE_URL
      });
    }
  }
</code></pre>
<ul>
<li>Initializes the client using <code class="inline-code">LLM_MODEL</code> and chooses credentials via <code class="inline-code">getApiKey</code>, failing fast if essential settings are missing.</li>
<li>Detects Azure semantics with <code class="inline-code">isAzureOpenAI</code> to correctly configure <code class="inline-code">AzureOpenAI</code> using endpoint, <code class="inline-code">LLM_API_VERSION</code>, and deployment.</li>
<li>Falls back to a standard <code class="inline-code">OpenAI</code> client when not on Azure, honoring <code class="inline-code">LLM_BASE_URL</code>.</li>
<li>Centralizes provider differences to keep call sites simple and uniform.</li>
<li>Establishes a robust foundation for transport that supports multiple providers cleanly.</li>
</ul>
<hr>
<pre><code class="language-typescript">  private getApiKey(): string {
    // GitHub Models (hosted on Azure) uses GITHUB_TOKEN
    if (LLM_BASE_URL.includes(&#39;models.inference.ai.azure.com&#39;)) {
      if (!GITHUB_TOKEN) {
        throw new Error(&#39;GITHUB_TOKEN required for GitHub Models. Set GITHUB_TOKEN environment variable.&#39;);
      }
      return GITHUB_TOKEN;
    }
    // All other providers (OpenAI, Azure OpenAI, Ollama, etc.) use LLM_API_KEY
    if (!LLM_API_KEY) {
      throw new Error(&#39;LLM_API_KEY required. Set LLM_API_KEY environment variable.&#39;);
    }
    return LLM_API_KEY;
  }
</code></pre>
<ul>
<li>Implements provider-aware credential selection keyed off <code class="inline-code">LLM_BASE_URL</code>.</li>
<li>Requires <code class="inline-code">GITHUB_TOKEN</code> for GitHub Models routed on Azure, otherwise uses <code class="inline-code">LLM_API_KEY</code>.</li>
<li>Provides clear, specific error messages for missing secrets, improving setup ergonomics.</li>
<li>Isolates authentication policy from request code, enabling simpler maintenance.</li>
<li>Encourages consistent environment configuration across deployments.</li>
</ul>
<hr>
<pre><code class="language-typescript">  private isAzureOpenAI(): boolean {
    return LLM_BASE_URL.includes(&#39;.openai.azure.com&#39;) || LLM_BASE_URL.includes(&#39;cognitiveservices.azure.com&#39;);
  }
</code></pre>
<ul>
<li>Detects Azure-native endpoints through hostname substrings, enabling conditional request configuration.</li>
<li>Keeps detection logic tightly scoped and testable, avoiding duplication in call paths.</li>
<li>Acts as a simple feature gate for Azure-specific request shape and client wiring.</li>
<li>Supports clear branching between <code class="inline-code">AzureOpenAI</code> and <code class="inline-code">OpenAI</code> implementations.</li>
<li>Minimizes coupling by relying only on <code class="inline-code">LLM_BASE_URL</code>.</li>
</ul>
<hr>
<pre><code class="language-typescript">  async generateResponse(prompt: string, options?: LLMRequestOptions): Promise&lt;LLMResponse&gt; {
    try {
      const requestParams = this.buildRequestParams(prompt, options);
      const completion = await this.executeRequest(requestParams);
      let content = this.validateResponse(completion);
      
      // Post-process JSON responses that might be wrapped in markdown
      if (options?.responseFormat === &#39;json_object&#39;) {
        content = this.cleanJsonResponse(content);
      }
      
      this.logTokenUsage(completion);
      
      return { content };
    } catch (error) {
      // Enhanced error logging for debugging
      this.logDetailedError(error, prompt);
      
      const message = error instanceof Error ? error.message : &#39;Unknown error&#39;;
      throw new Error(`LLM request failed: ${message}`);
    }
  }
</code></pre>
<ul>
<li>Orchestrates the full cycle: build params, execute with timeout, validate, post-process, and log usage.</li>
<li>Applies markdown-unwrapping for JSON responses, improving consumer ergonomics.</li>
<li>Uses <code class="inline-code">executeRequest</code> to wrap the provider call in a <code class="inline-code">Promise.race</code> with <code class="inline-code">LLM_REQUEST_TIMEOUT</code>.</li>
<li>Leans on <code class="inline-code">validateResponse</code> and specialized empty-response handling to ensure content quality.</li>
<li>Provides rich diagnostics with <code class="inline-code">logDetailedError</code>, turning mysterious failures into actionable clues.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Trace cache keys in <code class="inline-code">generateTargetedContent</code> to see how deterministic inputs accelerate repeated runs.</li>
<li>Compare <code class="inline-code">isAzureOpenAI</code> and <code class="inline-code">getApiKey</code> to understand how provider detection influences credentials and client instantiation.</li>
<li>Study <code class="inline-code">captureRepomixStdout</code>‚Äôs timeout and buffer guards to learn robust subprocess management patterns.</li>
</ul>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries.</p>
<p>Huzzah, valiant hero‚Äîby conquering Quest 3: Code Analysis &amp; Content Pipeline, you‚Äôve forged arcane mastery over the code-forge and content runes, advancing your kingdom‚Äôs grand saga to 2/5 quests (40%) with the thunder of triumph in your stride ‚ö°üíé.</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-2.html" class="prev-quest-btn">‚Üê Previous: Quest 2</a>
        <a href="quest-4.html" class="next-quest-btn">Next: Quest 4 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="assets/quest-navigator.js"></script>
</body>
</html>