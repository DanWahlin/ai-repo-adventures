<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Glyphs of Insight - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "tk53e05gf2");
    </script>
    
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }

        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-ancient">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/danwahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Pyramid of Code</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Adventure</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 4: The Glyphs of Insight</h1>
<hr>
<p>In the shadow of the Pyramid of Code&#39;s towering walls, you discover a hidden passage leading to the Chamber of Analysis. The air is thick with the scent of ancient parchment, and glowing glyphs illuminate the walls. These glyphs, created by the lost civilization of Codexians, hold the secrets of analyzing vast repositories and invoking the power of the LLM oracles. To unlock the chamber&#39;s treasure, you must decipher the glyphs and unravel their intricate mechanisms. Each glyph represents a function, a piece of wisdom waiting to be understood.</p>
<h2>Key Takeaways</h2>
<p>After completing this quest, you will understand:</p>
<ul>
<li>üéØ <strong>Content Optimization</strong>: How targeted file analysis reduces noise and improves efficiency in code exploration.</li>
<li>üîç <strong>LLM Integration</strong>: How to configure and interact with LLMs for dynamic content generation.</li>
<li>‚ö° <strong>Error Handling</strong>: Strategies for managing rate limits and ensuring robust LLM requests.</li>
<li>üí° <strong>Caching Mechanisms</strong>: How caching improves performance in repetitive operations like repository analysis.</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">packages/core/src/analyzer/repo-analyzer.ts</code></a></h3>
<p>The <code class="inline-code">RepoAnalyzer</code> class is the key to unlocking the Pyramid&#39;s ancient knowledge. It orchestrates repository analysis, leveraging tools like Repomix to extract targeted content. This file demonstrates techniques for validating input, optimizing content, and managing subprocesses efficiently. The methods explored here highlight how to balance performance with accuracy in large-scale code analysis.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L296" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateRepomixContext</code></a>: Generates repository context using Repomix, with fallback mechanisms for full or targeted content.</li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L246" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateTargetedContent</code></a>: Extracts specific files for analysis, ensuring security and efficiency through validation.</li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L610" target="_blank" rel="noopener noreferrer"><code class="inline-code">captureRepomixStdout</code></a>: Executes Repomix as a subprocess, capturing its output with timeout and memory safeguards.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">async generateRepomixContext(projectPath: string, options: RepomixOptions = {}): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);

  const configuredFiles = extractUniqueFilePaths(projectPath);

  if (configuredFiles.length &gt; 0) {
    try {
      return await this.generateOptimizedContent(projectPath, configuredFiles);
    } catch (error) {
      console.warn(`Failed to generate optimized content, falling back: ${error.message}`);
      return await this.generateTargetedContent(projectPath, configuredFiles);
    }
  }

  const cacheKey = `${path.resolve(projectPath)}:${JSON.stringify(options)}`;
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }

  const cliOptions: CliOptions = {
    style: options.style || &#39;markdown&#39;,
    compress: options.compress !== false,
    ignore: [&#39;node_modules&#39;, &#39;dist&#39;, &#39;.git&#39;],
    removeComments: true,
    removeEmptyLines: true,
  };

  const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
  this.cache.set(cacheKey, { content: context, timestamp: Date.now() });
  return context;
}
</code></pre>
<ul>
<li>This code dynamically generates repository context, prioritizing targeted content when available.</li>
<li>It employs caching to optimize performance, reducing redundant computations.</li>
<li>The fallback mechanism ensures robustness, even when optimizations fail.</li>
<li>CLI options are configured for efficient content extraction, removing unnecessary data.</li>
<li>The method demonstrates defensive programming through validation and error handling.</li>
</ul>
<hr>
<pre><code class="language-typescript">async generateTargetedContent(projectPath: string, targetFiles: string[], compress: boolean = true): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);

  const safeFiles = this.validateAndNormalizeTargetFiles(projectPath, targetFiles);
  if (safeFiles.length === 0) {
    throw new Error(&#39;No valid target files found after validation&#39;);
  }

  const cacheKey = `${path.resolve(projectPath)}:targeted:${safeFiles.join(&#39;,&#39;)}:compress=${compress}`;
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }

  const cliOptions: CliOptions = {
    style: &#39;markdown&#39;,
    compress,
    include: safeFiles.join(&#39;,&#39;),
    removeComments: compress,
    removeEmptyLines: compress,
  };

  const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
  this.cache.set(cacheKey, { content: context, timestamp: Date.now() });
  return context;
}
</code></pre>
<ul>
<li>This method focuses analysis on specific files, reducing noise and improving efficiency.</li>
<li>Validation ensures that only safe, existing files are processed, preventing security risks.</li>
<li>The use of CLI options tailors the analysis to the project&#39;s needs, enabling flexibility.</li>
<li>Caching further enhances performance, especially for repetitive operations.</li>
<li>The approach reflects best practices in handling large-scale codebases.</li>
</ul>
<hr>
<pre><code class="language-typescript">private async captureRepomixStdout(directories: string[], cwd: string, options: CliOptions): Promise&lt;string&gt; {
  return new Promise((resolve, reject) =&gt; {
    const args = [...directories, &#39;--stdout&#39;, &#39;--style&#39;, options.style || &#39;markdown&#39;];
    if (options.compress) args.push(&#39;--compress&#39;);
    if (options.removeComments) args.push(&#39;--remove-comments&#39;);

    const repomix = spawn(&#39;npx&#39;, [&#39;repomix&#39;, ...args], { cwd, stdio: [&#39;pipe&#39;, &#39;pipe&#39;, &#39;pipe&#39;] });
    let stdout = &#39;&#39;;
    let stderr = &#39;&#39;;

    repomix.stdout.on(&#39;data&#39;, (data) =&gt; {
      stdout += data.toString();
    });

    repomix.stderr.on(&#39;data&#39;, (data) =&gt; {
      stderr += data.toString();
    });

    repomix.on(&#39;close&#39;, (code) =&gt; {
      if (code === 0) {
        resolve(stdout);
      } else {
        reject(new Error(`Repomix failed with code ${code}: ${stderr}`));
      }
    });
  });
}
</code></pre>
<ul>
<li>This method executes Repomix as a subprocess, capturing its output for further processing.</li>
<li>It uses promises to handle asynchronous operations, ensuring reliability.</li>
<li>Error handling captures and logs issues, aiding in debugging.</li>
<li>The method demonstrates how to integrate external tools into a larger system.</li>
<li>Configurable options provide flexibility in execution, adapting to different use cases.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">packages/core/src/llm/llm-client.ts</code></a></h3>
<p>The <code class="inline-code">LLMClient</code> class acts as a conduit to the LLM oracles, enabling dynamic content generation. It abstracts API interactions, handles rate limits, and ensures robust error management. This file showcases techniques for integrating LLMs into applications while maintaining performance and reliability.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L140" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateResponse</code></a>: Sends prompts to the LLM and processes its response, including error handling.</li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L87" target="_blank" rel="noopener noreferrer"><code class="inline-code">constructor</code></a>: Initializes the client with appropriate configurations for the selected LLM provider.</li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L392" target="_blank" rel="noopener noreferrer"><code class="inline-code">detectRateLimitType</code></a>: Identifies rate limit errors and provides actionable feedback.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">async generateResponse(prompt: string, options?: LLMRequestOptions): Promise&lt;LLMResponse&gt; {
  await this.applyThrottling();

  try {
    const requestParams = this.buildRequestParams(prompt, options);
    const completion = await this.executeRequest(requestParams);
    let content = this.validateResponse(completion);

    if (options?.responseFormat === &#39;json_object&#39;) {
      content = this.cleanJsonResponse(content);
    }

    this.logTokenUsage(completion, options?.context);
    this.onSuccessfulRequest();

    return { content };
  } catch (error) {
    const rateLimitInfo = this.detectRateLimitType(error);

    if (rateLimitInfo.type !== RateLimitType.NONE) {
      this.activateThrottling(error);
      throw new RateLimitError(rateLimitInfo.type, rateLimitInfo.waitSeconds, rateLimitInfo.message, error);
    }

    this.logDetailedError(error, prompt);
    throw new Error(`LLM request failed: ${error.message}`);
  }
}
</code></pre>
<ul>
<li>This method encapsulates the entire process of sending a prompt and processing the response.</li>
<li>Throttling ensures compliance with rate limits, preventing overuse of resources.</li>
<li>Error handling provides detailed feedback, aiding in debugging and recovery.</li>
<li>The modular design allows for easy extension with new LLM providers or features.</li>
<li>Logging enhances transparency, making it easier to monitor and optimize usage.</li>
</ul>
<hr>
<pre><code class="language-typescript">constructor() {
  this.model = LLM_MODEL;

  const apiKey = this.getApiKey();
  if (!apiKey || !LLM_BASE_URL) {
    throw new Error(&#39;LLM configuration required. Please set the appropriate environment variables.&#39;);
  }

  if (this.isAzureOpenAI()) {
    const azureEndpoint = LLM_BASE_URL.split(&#39;/openai/deployments&#39;)[0];
    this.client = new AzureOpenAI({
      endpoint: azureEndpoint,
      apiKey,
      apiVersion: LLM_API_VERSION,
      deployment: this.model,
    });
  } else {
    this.client = new OpenAI({
      apiKey,
      baseURL: LLM_BASE_URL,
    });
  }
}
</code></pre>
<ul>
<li>The constructor initializes the client with configurations specific to the selected LLM provider.</li>
<li>It dynamically determines the API key and endpoint, supporting multiple providers.</li>
<li>Validation ensures that all required configurations are present, preventing runtime errors.</li>
<li>The design supports flexibility, enabling integration with future LLM providers.</li>
<li>This method demonstrates the importance of robust initialization in complex systems.</li>
</ul>
<hr>
<pre><code class="language-typescript">detectRateLimitType(error: any): RateLimitInfo {
  const errorMessage = error?.message || &#39;&#39;;
  const is429Error = error?.status === 429 || errorMessage.includes(&#39;429&#39;);

  if (!is429Error) {
    return { type: RateLimitType.NONE, waitSeconds: 0, message: &#39;&#39; };
  }

  if (errorMessage.includes(&#39;exceeded token rate limit&#39;)) {
    return {
      type: RateLimitType.TOKEN_RATE_EXCEEDED,
      waitSeconds: TOKEN_RATE_WINDOW_SECONDS,
      message: `Token rate limit exceeded (200K tokens/${TOKEN_RATE_WINDOW_SECONDS}s window)`,
    };
  }

  if (errorMessage.includes(&#39;retry after&#39;)) {
    const retryMatch = errorMessage.match(/retry after (\d+) seconds/);
    const waitSeconds = retryMatch ? parseInt(retryMatch[1]) : 60;

    return {
      type: RateLimitType.REQUEST_RATE_LIMIT,
      waitSeconds,
      message: `Request rate limit hit, retry after ${waitSeconds} seconds`,
    };
  }

  return { type: RateLimitType.REQUEST_RATE_LIMIT, waitSeconds: 60, message: &#39;429 rate limit encountered&#39; };
}
</code></pre>
<ul>
<li>This method identifies rate limit errors, providing actionable information for recovery.</li>
<li>It distinguishes between token and request rate limits, tailoring responses accordingly.</li>
<li>The implementation highlights the importance of detailed error analysis in API integrations.</li>
<li>By centralizing rate limit detection, the method simplifies error handling across the system.</li>
<li>This approach ensures a consistent and user-friendly experience during rate-limited scenarios.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Use <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L246" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateTargetedContent</code></a> to focus analysis on specific files, reducing noise and improving performance.</li>
<li>Study the <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L140" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateResponse</code></a> method to understand how to handle LLM interactions, including error recovery.</li>
<li>Explore the caching mechanisms in <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L296" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateRepomixContext</code></a> to see how repeated operations are optimized.</li>
</ul>
<h2>Try This</h2>
<p>Challenge yourself to deepen your understanding:</p>
<ol>
<li><p><strong>Add Custom Validation</strong>: Modify <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L150" target="_blank" rel="noopener noreferrer"><code class="inline-code">validateAndNormalizeTargetFiles</code></a> to reject files based on additional patterns, such as <code class="inline-code">.env</code> files. Test the updated validation logic with a sample project.</p>
</li>
<li><p><strong>Simulate Rate Limits</strong>: Introduce artificial delays in <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L140" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateResponse</code></a> to simulate rate limits. Observe how the throttling mechanism adapts and prevents excessive requests.</p>
</li>
<li><p><strong>Extend LLMClient</strong>: Add support for a new LLM provider by extending the <code class="inline-code">LLMClient</code> constructor. Implement custom configurations and test the integration with a sample prompt.</p>
</li>
</ol>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries hidden within the Pyramid of Code.</p>
<p>Hail, seeker of wisdom, for the sacred Glyphs of Insight now illuminate thy path‚Äîpress onward, for the stars themselves bear witness to thy triumph! ‚≠ê‚ö°üó∫Ô∏è</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-3.html" class="prev-quest-btn">‚Üê Previous: Quest 3</a>
        <a href="quest-5.html" class="next-quest-btn">Next: Quest 5 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>