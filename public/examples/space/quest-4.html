<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Code Analysis Systems - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "tk53e05gf2");
    </script>
    
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }

        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-space">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/danwahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">Galactic Code Odyssey</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Adventure</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 4: Code Analysis Systems</h1>
<hr>
<p>The starship <em>Code Voyager</em> drifts into the heart of the Encrypted Nebula, where ancient code fragments swirl like cosmic dust. Your mission is to unlock the secrets of the Repository Analyzer and the LLM Client, two critical systems that power the ship‚Äôs ability to interpret and generate actionable intelligence from the repository. With the Quantum Quest Generator humming in anticipation, you must ensure these systems function seamlessly, enabling the crew to decode the nebula‚Äôs mysteries and advance the Galactic Knowledge Network.</p>
<h2>Key Takeaways</h2>
<p>After completing this quest, you will understand:  </p>
<ul>
<li>üéØ <strong>Content Optimization</strong>: How <code class="inline-code">RepoAnalyzer</code> generates targeted and optimized content for efficient analysis.  </li>
<li>üîç <strong>LLM Integration</strong>: How the <code class="inline-code">LLMClient</code> interfaces with multiple providers to generate responses dynamically.  </li>
<li>‚ö° <strong>Error Handling Patterns</strong>: Techniques for managing rate limits and ensuring robust operations under constraints.  </li>
<li>üí° <strong>Caching Strategies</strong>: How caching is used to reduce redundant operations and improve performance.</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">packages/core/src/analyzer/repo-analyzer.ts</code></a></h3>
<p>The <code class="inline-code">RepoAnalyzer</code> module is the ship‚Äôs primary tool for analyzing repositories. It uses the Repomix subprocess to extract and optimize content, ensuring only the most relevant code and documentation are included. The analyzer also implements robust validation and caching mechanisms to handle large codebases efficiently.  </p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L296" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateRepomixContext</code></a> orchestrates the full analysis process, including fallback mechanisms for different content types.  </li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L246" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateTargetedContent</code></a> extracts specific files from the repository for focused analysis, ensuring security and reliability.  </li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L610" target="_blank" rel="noopener noreferrer"><code class="inline-code">captureRepomixStdout</code></a> executes the Repomix subprocess with timeout and memory protection, capturing its output for further processing.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">async generateRepomixContext(projectPath: string, options: RepomixOptions = {}): Promise&lt;string&gt; {
  this.validateProjectPath(projectPath);

  const configuredFiles = extractUniqueFilePaths(projectPath);

  if (configuredFiles.length &gt; 0) {
    try {
      return await this.generateOptimizedContent(projectPath, configuredFiles);
    } catch (error) {
      console.warn(`Failed to generate optimized content, falling back to targeted content: ${error.message}`);
      return await this.generateTargetedContent(projectPath, configuredFiles);
    }
  }

  const cacheKey = `${path.resolve(projectPath)}:${JSON.stringify(options)}`;
  const cached = this.cache.get(cacheKey);
  if (cached &amp;&amp; (Date.now() - cached.timestamp) &lt; REPOMIX_CACHE_TTL) {
    return cached.content;
  }

  const cliOptions: CliOptions = {
    style: options.style || &#39;markdown&#39;,
    stdout: true,
    compress: options.compress !== false,
    ignore: [&#39;node_modules&#39;, &#39;dist&#39;, &#39;build&#39;, &#39;.git&#39;, &#39;coverage&#39;].join(&#39;,&#39;),
    removeComments: true,
    removeEmptyLines: true,
    noDirectoryStructure: true
  };

  const context = await this.captureRepomixStdout([&#39;.&#39;], projectPath, cliOptions);
  this.cache.set(cacheKey, { content: context, timestamp: Date.now() });

  return context;
}
</code></pre>
<ul>
<li>This function handles the end-to-end process of generating repository context, including fallback strategies.  </li>
<li>It checks for pre-configured files via <code class="inline-code">adventure.config.json</code> and optimizes content extraction accordingly.  </li>
<li>Caching ensures repeated operations on the same repository are efficient.  </li>
<li>The use of CLI options allows flexible adjustments to content extraction parameters.  </li>
<li>The fallback mechanism demonstrates resilience by handling errors gracefully.</li>
</ul>
<hr>
<pre><code class="language-typescript">async captureRepomixStdout(directories: string[], cwd: string, options: CliOptions): Promise&lt;string&gt; {
  return new Promise((resolve, reject) =&gt; {
    const repomix = spawn(&#39;npx&#39;, [&#39;repomix&#39;, ...directories, &#39;--stdout&#39;, &#39;--style&#39;, options.style || &#39;markdown&#39;], { cwd });

    let stdout = &#39;&#39;;
    let stderr = &#39;&#39;;
    repomix.stdout.on(&#39;data&#39;, (data) =&gt; (stdout += data.toString()));
    repomix.stderr.on(&#39;data&#39;, (data) =&gt; (stderr += data.toString()));

    repomix.on(&#39;close&#39;, (code) =&gt; {
      if (code === 0) {
        resolve(stdout);
      } else {
        reject(new Error(`Repomix failed with code ${code}: ${stderr}`));
      }
    });
  });
}
</code></pre>
<ul>
<li>This function executes the Repomix tool as a subprocess, capturing its output for further processing.  </li>
<li>It uses event listeners to handle both standard output and error streams.  </li>
<li>The promise-based implementation ensures asynchronous execution with error handling.  </li>
<li>The subprocess approach allows integration with external tools while maintaining control over execution.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">packages/core/src/llm/llm-client.ts</code></a></h3>
<p>The <code class="inline-code">LLMClient</code> serves as the ship‚Äôs communication system with external LLM providers. It abstracts the complexities of API interactions, supporting multiple providers like OpenAI and Azure OpenAI. The client also implements adaptive throttling and error handling to manage rate limits effectively.  </p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L140" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateResponse</code></a> sends prompts to the LLM and processes the responses, including error handling and post-processing.  </li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L392" target="_blank" rel="noopener noreferrer"><code class="inline-code">detectRateLimitType</code></a> identifies rate-limiting scenarios and provides actionable information for recovery.  </li>
<li><a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L462" target="_blank" rel="noopener noreferrer"><code class="inline-code">applyThrottling</code></a> introduces adaptive delays to manage request rates and ensure compliance with provider limits.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">async generateResponse(prompt: string, options?: LLMRequestOptions): Promise&lt;LLMResponse&gt; {
  await this.applyThrottling();

  try {
    const requestParams = this.buildRequestParams(prompt, options);
    const completion = await this.executeRequest(requestParams);
    let content = this.validateResponse(completion);

    if (options?.responseFormat === &#39;json_object&#39;) {
      content = this.cleanJsonResponse(content);
    }

    this.onSuccessfulRequest();
    return { content };
  } catch (error) {
    const rateLimitInfo = this.detectRateLimitType(error);

    if (rateLimitInfo.type !== RateLimitType.NONE) {
      this.activateThrottling(error);
      throw new RateLimitError(rateLimitInfo.type, rateLimitInfo.waitSeconds, rateLimitInfo.message, error);
    }

    throw new Error(`LLM request failed: ${error.message}`);
  }
}
</code></pre>
<ul>
<li>This function handles the entire lifecycle of an LLM request, from building parameters to processing responses.  </li>
<li>It integrates adaptive throttling to manage provider rate limits effectively.  </li>
<li>Post-processing ensures responses are clean and usable, especially for JSON outputs.  </li>
<li>The use of custom error classes improves error handling and debugging.</li>
</ul>
<hr>
<pre><code class="language-typescript">detectRateLimitType(error: any): RateLimitInfo {
  const errorMessage = error?.message || &#39;&#39;;
  const is429Error = error?.status === 429 || errorMessage.includes(&#39;429&#39;);

  if (!is429Error) {
    return { type: RateLimitType.NONE, waitSeconds: 0, message: &#39;&#39; };
  }

  if (errorMessage.includes(&#39;retry after&#39;)) {
    const retryMatch = errorMessage.match(/retry after (\d+) seconds/);
    const waitSeconds = retryMatch ? parseInt(retryMatch[1]) : 60;

    return {
      type: RateLimitType.REQUEST_RATE_LIMIT,
      waitSeconds,
      message: `Request rate limit hit, retry after ${waitSeconds} seconds`
    };
  }

  return { type: RateLimitType.REQUEST_RATE_LIMIT, waitSeconds: 60, message: &#39;429 rate limit encountered&#39; };
}
</code></pre>
<ul>
<li>This function identifies different types of rate-limiting errors and extracts actionable information.  </li>
<li>It parses error messages to determine appropriate wait times for retries.  </li>
<li>The structured return value simplifies integration with other parts of the system.  </li>
<li>This approach ensures the system can adapt dynamically to provider constraints.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Explore how <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/analyzer/repo-analyzer.ts#L296" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateRepomixContext</code></a> uses fallback mechanisms to handle errors and ensure robustness.  </li>
<li>Study the <a href="https://github.com/danwahlin/ai-repo-adventures/blob/main/packages/core/src/llm/llm-client.ts#L140" target="_blank" rel="noopener noreferrer"><code class="inline-code">generateResponse</code></a> method to understand how adaptive throttling improves system reliability.  </li>
<li>Review the caching strategies in <code class="inline-code">RepoAnalyzer</code> to see how they optimize performance in large repositories.</li>
</ul>
<h2>Try This</h2>
<p>Challenge yourself to deepen your understanding:  </p>
<ol>
<li><p><strong>Add New Caching Logic</strong>: Modify the <code class="inline-code">RepoAnalyzer</code> to include a longer cache TTL for specific file types. Observe how this impacts performance during repeated analyses.  </p>
</li>
<li><p><strong>Simulate Rate Limits</strong>: Introduce artificial rate limits in the <code class="inline-code">LLMClient</code> and test how the adaptive throttling mechanism manages delays.  </p>
</li>
<li><p><strong>Enhance Error Logging</strong>: Extend the error logging in <code class="inline-code">LLMClient</code> to include more diagnostic information, such as request parameters and timestamps.</p>
</li>
</ol>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the starship‚Äôs systems.</p>
<p>Mission accomplished, star voyager! Your mastery of Code Analysis Systems has propelled you 60% closer to your cosmic quest, shining brighter than a supernova‚Äîkeep rocketing toward the stars! üöÄ‚≠ê‚ö°</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-3.html" class="prev-quest-btn">‚Üê Previous: Quest 3</a>
        <a href="quest-5.html" class="next-quest-btn">Next: Quest 5 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>